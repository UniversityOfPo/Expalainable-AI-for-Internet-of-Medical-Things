# Expalainable-AI-for-Internet-of-Medical-Things
This work presents a novel Explainable Artificial Intelligence (XAI) framework designed specifically for the Artificial Intelligence of Medical Things (AIoMT). The framework incorporates techniques like Local Interpretable Model-Agnostic Explanations (LIME), SHapley Additive exPlanations (SHAP), and Gradient-weighted Class Activation Mapping (Grad-CAM), aiming to provide transparent and interpretable decision-making in healthcare systems. It enhances existing healthcare strategies and fosters trust in AI-driven medical applications. The framework also employs a majority voting method utilizing the combined intelligence of multiple convolutional neural networks (CNNs) for reliable decision-making. This XAI framework has been applied successfully to brain tumor detection, demonstrating its effectiveness with a training accuracy of 99% and a validation accuracy of 98%. The application of XAI techniques along with ensemble-based deep learning methodologies ensures precise and trustworthy brain tumor diagnoses in AIoMT.
